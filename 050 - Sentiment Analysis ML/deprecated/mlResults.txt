R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> install.packages(c("ggplot2", "RODBC","devtools", "RTextTools", "caret"))
Installing packages into ‘C:/Users/hupse/Documents/R/win-library/3.4’
(as ‘lib’ is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/ggplot2_2.2.1.zip'
Content type 'application/zip' length 2784094 bytes (2.7 MB)
downloaded 2.7 MB

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/RODBC_1.3-15.zip'
Content type 'application/zip' length 831635 bytes (812 KB)
downloaded 812 KB

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/devtools_1.13.4.zip'
Content type 'application/zip' length 443915 bytes (433 KB)
downloaded 433 KB

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/RTextTools_1.4.2.zip'
Content type 'application/zip' length 540154 bytes (527 KB)
downloaded 527 KB

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/caret_6.0-78.zip'
Content type 'application/zip' length 5155372 bytes (4.9 MB)
downloaded 4.9 MB

package ‘ggplot2’ successfully unpacked and MD5 sums checked
package ‘RODBC’ successfully unpacked and MD5 sums checked
package ‘devtools’ successfully unpacked and MD5 sums checked
Warning in install.packages :
  unable to move temporary installation ‘C:\Users\hupse\Documents\R\win-library\3.4\file2310494b68f6\devtools’ to ‘C:\Users\hupse\Documents\R\win-library\3.4\devtools’
package ‘RTextTools’ successfully unpacked and MD5 sums checked
package ‘caret’ successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\hupse\AppData\Local\Temp\Rtmp4iepJL\downloaded_packages
> 
> library("RODBC")
> library("devtools")
Error in library("devtools") : there is no package called ‘devtools’
> library("RTextTools")
Loading required package: SparseM

Attaching package: ‘SparseM’

The following object is masked from ‘package:base’:

    backsolve

> library("e1071")
> library("caret")
Loading required package: lattice
Loading required package: ggplot2
> options(scipen = 999)
> conn <- odbcDriverConnect('driver={SQL Server};server=localhost\\SQLEXPRESS;database=iPhoneXReleaseTweets;
+                           trusted_connection=true')
> 
> positive_all = sqlQuery(conn, "SELECT TOP 1500 [tweet]
+ FROM dbo.CrowdFlower AS TESTDATA
+                  WHERE (relevant_yn LIKE 'yes') AND (relevant_yn_confidence = 1) AND (sentiment_confidence > 0.6) AND (sentiment LIKE 'positive') 
+                  ORDER BY NEWID()"
+                  , as.is = TRUE)
> positive = positive_all[1:1400,]
> positive_test = positive_all[1401:1500,]
> 
> negative_all = sqlQuery(conn, "SELECT TOP 1500 [tweet]
+ FROM dbo.CrowdFlower AS TESTDATA
+                  WHERE (relevant_yn LIKE 'yes') AND (relevant_yn_confidence = 1) AND (sentiment_confidence > 0.6) AND (sentiment LIKE 'negative') 
+                  ORDER BY NEWID()"
+                        , as.is = TRUE)
> negative = negative_all[1:1400,]
> negative_test = negative_all[1401:1500,]
> 
> #######################################################################################
> 
> tweet = c(positive, negative)
> tweet_test= c(positive_test, negative_test)
> tweet_all = c(tweet, tweet_test)
> 
> sentiment = c(rep("positive", length(positive) ), 
+               rep("negative", length(negative)))
> 
> sentiment_test = c(rep("positive", length(positive_test) ), 
+                    rep("negative", length(negative_test)))
> 
> sentiment_all = as.factor(c(sentiment, sentiment_test))
> library(RTextTools)
> # the other methods
> mat= create_matrix(tweet_all, language="english", 
+                    removeStopwords=TRUE, removeNumbers=TRUE, removePunctuation=TRUE, toLower=TRUE, removeSparseTerms=0.999,
+                    stemWords=TRUE, tm::weightTf)
> 
> container = create_container(mat, as.numeric(sentiment_all),
+                              trainSize=1:2800, testSize=2801:3000,virgin=FALSE)
> models = train_models(container, algorithms=c("MAXENT","SVM", "RF"),
+                       method = "eps-classification", #SVM
+                       cross = 20, #SVM
+                       cost = 100, #SVM
+                       kernel= "radial", #SVM
+                       #l1_regularizer= 0, #MAXENT
+                       l2_regularizer = 1, #MAXENT
+                       #use_sgd = FALSE, #MAXENT
+                       #set_heldout = 0, #MAXENT
+                       verbose = FALSE) #MAXENT
> results = classify_models(container, models)
> analytics = create_analytics(container, results)
> summary(analytics)
ENSEMBLE SUMMARY

       n-ENSEMBLE COVERAGE n-ENSEMBLE RECALL
n >= 1                1.00              0.82
n >= 2                1.00              0.82
n >= 3                0.86              0.88


ALGORITHM PERFORMANCE

       SVM_PRECISION           SVM_RECALL           SVM_FSCORE    FORESTS_PRECISION       FORESTS_RECALL       FORESTS_FSCORE 
               0.790                0.790                0.785                0.840                0.840                0.835 
MAXENTROPY_PRECISION    MAXENTROPY_RECALL    MAXENTROPY_FSCORE 
               0.840                0.840                0.835 
> head(analytics@algorithm_summary)
  SVM_PRECISION SVM_RECALL SVM_FSCORE FORESTS_PRECISION FORESTS_RECALL FORESTS_FSCORE MAXENTROPY_PRECISION MAXENTROPY_RECALL
1          0.81       0.76       0.78              0.83           0.86           0.84                 0.86              0.81
2          0.77       0.82       0.79              0.85           0.82           0.83                 0.82              0.87
  MAXENTROPY_FSCORE
1              0.83
2              0.84
> head(analytics@label_summary)
  NUM_MANUALLY_CODED NUM_CONSENSUS_CODED NUM_PROBABILITY_CODED PCT_CONSENSUS_CODED PCT_PROBABILITY_CODED PCT_CORRECTLY_CODED_CONSENSUS
1                100                  97                    97                  97                    97                            81
2                100                 103                   103                 103                   103                            84
  PCT_CORRECTLY_CODED_PROBABILITY
1                              80
2                              83
> head(analytics@document_summary)
  MAXENTROPY_LABEL MAXENTROPY_PROB SVM_LABEL  SVM_PROB FORESTS_LABEL FORESTS_PROB MANUAL_CODE CONSENSUS_CODE CONSENSUS_AGREE
1                1       0.8480729         1 0.8256165             1        0.675           2              1               3
2                2       0.8628093         2 0.8725371             2        0.965           2              2               3
3                2       0.7295932         2 0.7863786             2        0.925           2              2               3
4                2       0.6372032         1 0.5404991             1        0.520           2              1               2
5                2       0.7169170         2 0.7192604             2        0.655           2              2               3
6                2       0.9050433         2 0.9642441             2        0.990           2              2               3
  CONSENSUS_INCORRECT PROBABILITY_CODE PROBABILITY_INCORRECT
1                   1                1                     1
2                   0                2                     0
3                   0                2                     0
4                   1                2                     0
5                   0                2                     0
6                   0                2                     0
> analytics@ensemble_summary
       n-ENSEMBLE COVERAGE n-ENSEMBLE RECALL
n >= 1                1.00              0.82
n >= 2                1.00              0.82
n >= 3                0.86              0.88
> table(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"SVM_LABEL"])
   
     1  2
  1 76 24
  2 18 82
> recall_accuracy(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"SVM_LABEL"])
[1] 0.79
> confusionMatrix(table(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"SVM_LABEL"]))
Confusion Matrix and Statistics

   
     1  2
  1 76 24
  2 18 82
                                             
               Accuracy : 0.79               
                 95% CI : (0.7269, 0.8443)   
    No Information Rate : 0.53               
    P-Value [Acc > NIR] : 0.00000000000001978
                                             
                  Kappa : 0.58               
 Mcnemar's Test P-Value : 0.4404             
                                             
            Sensitivity : 0.8085             
            Specificity : 0.7736             
         Pos Pred Value : 0.7600             
         Neg Pred Value : 0.8200             
             Prevalence : 0.4700             
         Detection Rate : 0.3800             
   Detection Prevalence : 0.5000             
      Balanced Accuracy : 0.7910             
                                             
       'Positive' Class : 1                  
                                             
> 
> table(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"MAXENTROPY_LABEL"])
   
     1  2
  1 81 19
  2 13 87
> recall_accuracy(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"MAXENTROPY_LABEL"])
[1] 0.84
> confusionMatrix(table(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"MAXENTROPY_LABEL"]))
Confusion Matrix and Statistics

   
     1  2
  1 81 19
  2 13 87
                                             
               Accuracy : 0.84               
                 95% CI : (0.7817, 0.8879)   
    No Information Rate : 0.53               
    P-Value [Acc > NIR] : <0.0000000000000002
                                             
                  Kappa : 0.68               
 Mcnemar's Test P-Value : 0.3768             
                                             
            Sensitivity : 0.8617             
            Specificity : 0.8208             
         Pos Pred Value : 0.8100             
         Neg Pred Value : 0.8700             
             Prevalence : 0.4700             
         Detection Rate : 0.4050             
   Detection Prevalence : 0.5000             
      Balanced Accuracy : 0.8412             
                                             
       'Positive' Class : 1                  
                                             
> 
> table(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"FORESTS_LABEL"])
   
     1  2
  1 86 14
  2 18 82
> recall_accuracy(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"FORESTS_LABEL"])
[1] 0.84
> confusionMatrix(table(as.numeric(as.numeric(sentiment_all[2801:3000])), results[,"FORESTS_LABEL"]))
Confusion Matrix and Statistics

   
     1  2
  1 86 14
  2 18 82
                                             
               Accuracy : 0.84               
                 95% CI : (0.7817, 0.8879)   
    No Information Rate : 0.52               
    P-Value [Acc > NIR] : <0.0000000000000002
                                             
                  Kappa : 0.68               
 Mcnemar's Test P-Value : 0.5959             
                                             
            Sensitivity : 0.8269             
            Specificity : 0.8542             
         Pos Pred Value : 0.8600             
         Neg Pred Value : 0.8200             
             Prevalence : 0.5200             
         Detection Rate : 0.4300             
   Detection Prevalence : 0.5000             
      Balanced Accuracy : 0.8405             
                                             
       'Positive' Class : 1 